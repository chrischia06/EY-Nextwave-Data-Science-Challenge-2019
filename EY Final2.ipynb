{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "\n",
    "#read csv files\n",
    "df = pd.read_csv(\"data_train.csv\")\n",
    "df2 = pd.read_csv(\"data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_transform(df2):\n",
    "    df = df2.copy()\n",
    "    df[[\"hour_entry\", \"minute_entry\", \"second_entry\"]] = df[\"time_entry\"].str.extract(r'(\\d+):(\\d+):(\\d+)').astype(int)\n",
    "    df[[\"hour_exit\", \"minute_exit\", \"second_exit\"]] = df[\"time_exit\"].str.extract(r'(\\d+):(\\d+):(\\d+)').astype(int)\n",
    "    df[\"t_nm1\"] = (3600 * df[\"hour_entry\"] + 60 * df[\"minute_entry\"] + df[\"second_entry\"]) \n",
    "    df[\"t_n\"] = (3600 * df[\"hour_exit\"] + 60 * df[\"minute_exit\"] + df[\"second_exit\"])\n",
    "    \n",
    "    [x_lower, x_upper, y_lower, y_upper] = [3750901.5068,3770901.5068, -19268905.6133,-19208905.6133]\n",
    "    df[\"target\"] =  ((df[\"x_exit\"] >= x_lower) & (df[\"x_exit\"] <= x_upper) & \\\n",
    "                             (df[\"y_exit\"] >= y_lower) &  (df[\"y_exit\"] <= y_upper)) * 1\n",
    "    \n",
    "    targets = df[df['hour_exit'] >= 15][['trajectory_id','x_exit','y_exit','target']]\n",
    "    df.loc[df['hour_exit'] >= 15,['x_exit','y_exit']] = np.nan\n",
    "    \n",
    "    unwanted = ['Unnamed: 0', 'Unnamed: 0.1','vmean','vmin','vmax','time_entry','time_exit',\n",
    "               'hour_entry','hour_exit','minute_entry','minute_exit','second_entry','second_exit','target']\n",
    "    return df.drop(unwanted,axis=1).rename(index=str,columns={\"trajectory_id\":\"id\"}),\\\n",
    "           targets.rename(index=str,columns={\"trajectory_id\":\"id\"})\n",
    "\n",
    "#process data\n",
    "df_copy, targets = df_transform(df)\n",
    "df2_copy, targets2 = df_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate(df):\n",
    "    df_copy = df.copy()\n",
    "    X = df_copy[['hash','id','x_entry','y_entry','t_nm1']]\n",
    "    X2 = df_copy[['hash','id','x_exit','y_exit','t_n']]\n",
    "    X.columns = ['hash','id','x','y','t']\n",
    "    X2.columns = ['hash','id','x','y','t']\n",
    "    X3 = pd.concat([X,X2])\n",
    "    X3 = X3.drop_duplicates(subset=['hash','id','x','t'],keep='last')\n",
    "    X3 = X3.sort_values(by='t',kind='mergesort')\n",
    "    X3['n'] = X3.groupby(['hash']).cumcount()\n",
    "    X3['n2'] = X3.groupby(['hash']).cumcount(ascending=False)\n",
    "    \n",
    "    final = X3[X3['n2'] == 0][['hash','id','t','n','n2']]\n",
    "    right = pd.DataFrame(X3.groupby(['hash'])['x'].apply(lambda x : np.nansum(np.abs(np.diff(x)))))\n",
    "    right.columns = ['absum_dx']                \n",
    "    final = pd.merge(final,right,left_on='hash',right_index=True,how='inner')\n",
    "    right = pd.DataFrame(X3.groupby(['hash'])['y'].apply(lambda x : np.nansum(np.abs(np.diff(x)))))\n",
    "    right.columns = ['absum_dy']\n",
    "    final = pd.merge(final,right,left_on='hash',right_index=True,how='inner')\n",
    "    \n",
    "    params = ['x_nm','y_nm','t_nm']\n",
    "    for i in range (1,4):\n",
    "        current_params = [x+str(i) for x in params]\n",
    "        right = X3[X3['n2'] == i][['hash','x','y','t']]\n",
    "        right.columns = ['hash'] + current_params\n",
    "        final = pd.merge(final,right,left_on='hash',right_on='hash',how='outer')\n",
    "\n",
    "    params = ['x_','y_','t_']\n",
    "\n",
    "    for i in range (0,2):\n",
    "        current_params = [x+str(i) for x in params]\n",
    "        right = X3[X3['n'] == i][['hash','x','y','t']]\n",
    "        right.columns = ['hash'] + current_params\n",
    "        final = pd.merge(final,right,left_on='hash',right_on='hash',how='outer')\n",
    "    return final.drop(['hash','n2'],axis=1)\n",
    "\n",
    "    #fill values with not enough length\n",
    "\n",
    "final = aggregate(df_copy)\n",
    "final2 = aggregate(df2_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_transform2(final, targets):\n",
    "    data = final.copy()\n",
    "    [x_lower, x_upper, y_lower, y_upper] = [3750901.5068,3770901.5068, -19268905.6133,-19208905.6133]\n",
    "    data['dt'] = data['t'] - data['t_nm1']\n",
    "    data['sum_dt'] = data['t'] - data['t_0']\n",
    "    data['dist'] = np.sqrt(data['absum_dy'] * data['absum_dy'] + data['absum_dx'] * data['absum_dx'])\n",
    "\n",
    "    data['in_entry'] = ((data[\"x_nm1\"] >= x_lower) & (data[\"x_nm1\"] <= x_upper) & \\\n",
    "                                 (data[\"y_nm1\"] >= y_lower) &  (data[\"y_nm1\"] <= y_upper)) * 1\n",
    "    #data.loc[data['x_nm2'].isna() == True,'x_nm2'] = data.loc[data['x_nm2'].isna() == True,'x_nm1']\n",
    "#data.loc[data['y_nm2'].isna() == True,'y_nm2'] = data.loc[data['y_nm2'].isna() == True,'y_nm1']\n",
    "#data.loc[data['x_nm3'].isna() == True,'x_nm3'] = data.loc[data['x_nm3'].isna() == True,'x_nm2']\n",
    "#data.loc[data['y_nm3'].isna() == True,'y_nm3'] = data.loc[data['y_nm3'].isna() == True,'y_nm2']\n",
    "    \n",
    "    data['dx'] = data['x_nm1'] - data['x_nm2']\n",
    "    data['dy'] = data['y_nm1'] - data['y_nm2']\n",
    "    data['dx2'] = data['x_1'] - data['x_0']\n",
    "    data['dy2'] = data['y_1'] - data['y_0']\n",
    "    data['dx3'] = data['x_nm1'] - data['x_0']\n",
    "    data['dy3'] = data['y_nm1'] - data['y_0']\n",
    "    data['dx4'] = data['x_nm1'] - data['x_nm3']\n",
    "    data['dy4'] = data['y_nm1'] - data['y_nm3']\n",
    "\n",
    "    return data\n",
    "\n",
    "final = df_transform2(final,targets)\n",
    "final2 = df_transform2(final2,targets2)\n",
    "data = pd.merge(final,targets,left_on='id',right_on='id',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0.885202450180633\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "#Best - CV 0.8870269975190004, Train 0.9619019941600586, n_estimators = 200, max_depth = 9, gamma = 0.5\n",
    "# CV - 0.8878599904986961, 0.915913887716336 - n_estimators = 100, max_depth = 8, gamma=0.3\n",
    "#CV - 0.8872853828082421, Train: 0.9491159026661493- n_estimators = 100, max_depth = 10, gamma =0.2\n",
    "\n",
    "features2 = ['x_nm1','y_nm1','dt','x_nm2','y_nm2','x_nm3','y_nm3',\n",
    "             'x_0','y_0','dist','t_0','y_1','x_1','t_1'] +\\\n",
    "            ['dx','dy','dx2','dy2','dx4','dy4']\n",
    "\n",
    "features = ['x_nm1','y_nm1','dt','x_nm3','y_nm3',\n",
    "             'x_0','y_0','dist','t_0','y_1','x_1','t_1'] +\\\n",
    "            ['dx','dy','dx2','dy2','dx4','dy4','t_nm1']\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "xgbc=xgb.XGBClassifier(n_estimators=200, max_depth=9,gamma=0.5,scale_pos_weights=2.5) \n",
    "print(\"CV: {}\".format(cross_val_score(xgbc,data[features],data[\"target\"],cv=2,scoring=\"f1\").mean()))\n",
    "\n",
    "xgbc.fit(data[features],data[\"target\"])\n",
    "xgb.plot_importance(xgbc)\n",
    "data['test'] = xgbc.predict(data[features])\n",
    "print(\"Train: {}\".format(f1_score(data['target'],data['test'])))\n",
    "pd.crosstab(data['test'],data['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 't', 'n', 'absum_dx', 'absum_dy', 'x_nm1', 'y_nm1', 't_nm1',\n",
       "       'x_nm2', 'y_nm2', 't_nm2', 'x_nm3', 'y_nm3', 't_nm3', 'x_0', 'y_0',\n",
       "       't_0', 'x_1', 'y_1', 't_1', 'dt', 'sum_dt', 'dist', 'in_entry', 'dx',\n",
       "       'dy', 'dx2', 'dy2', 'dx3', 'dy3', 'dx4', 'dy4', 'x_exit', 'y_exit',\n",
       "       'target', 'test'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 't', 'n', 'absum_dx', 'absum_dy', 'x_nm1', 'y_nm1', 't_nm1',\n",
       "       'x_nm2', 'y_nm2', 't_nm2', 'x_nm3', 'y_nm3', 't_nm3', 'x_0', 'y_0',\n",
       "       't_0', 'x_1', 'y_1', 't_1', 'dt', 'sum_dt', 'dist', 'in_entry', 'dx',\n",
       "       'dy', 'dx2', 'dy2', 'dx3', 'dy3', 'dx4', 'dy4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2['target'] = xgbc.predict(final2[features])\n",
    "#final2 = final2.set_index('id')\n",
    "final2['target'].to_csv(\"output.csv\",index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(df):\n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    \n",
    "    for x in range(1,4):\n",
    "        df_copy['norm_xnm' + str(x)] = (df_copy['x_nm'+str(i)] - df_copy['x_nm1'].mean()) / df_copy['x_nm1'].std()\n",
    "        df_copy['norm_ynm' + str(x)] = (df_copy['y_nm'+str(i)] - df_copy['y_nm1'].mean()) / df_copy['y_nm1'].std()\n",
    "    \n",
    "    df_copy['norm_x0'] = (df_copy['x_0'] - df_copy['x_nm1'].mean()) / df_copy['x_nm1'].mean()\n",
    "    df_copy['norm_y0'] = (df_copy['y_0'] - df_copy['y_nm1'].mean()) / df_copy['y_nm1'].mean()\n",
    "    df_copy['norm_dt'] = (df_copy['dt'] - df_copy['dt'].mean()) / df_copy['dt'].std()\n",
    "    \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data['x_nm2'].isna() == True,'x_nm2'] = data.loc[data['x_nm2'].isna() == True,'x_nm1']\n",
    "data.loc[data['y_nm2'].isna() == True,'y_nm2'] = data.loc[data['y_nm2'].isna() == True,'y_nm1']\n",
    "data.loc[data['x_nm3'].isna() == True,'x_nm3'] = data.loc[data['x_nm3'].isna() == True,'x_nm2']\n",
    "data.loc[data['y_nm3'].isna() == True,'y_nm3'] = data.loc[data['y_nm3'].isna() == True,'y_nm2']\n",
    "\n",
    "\n",
    "normfeatures = ['norm_xnm1', 'norm_ynm1','norm_x0','norm_y0','norm_xnm2','norm_ynm2','norm_xnm3','norm_ynm3']\n",
    "test = normalise(data)\n",
    "test2 = test[test['dt'] > 0]\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
