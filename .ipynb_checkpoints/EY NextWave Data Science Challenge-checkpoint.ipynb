{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief ##\n",
    "Global urbanisation is rising, 50% of world pop lives in cities, expected to rise to 60% by 2030 accordign to UN - which is 1.5 billion more than in 2010\n",
    "\n",
    "How do countries upgrade infrastructure, alleviate congestion, pollution? Electric and autonomous vehicles are helping to address these challenges, but are only the beginninng\n",
    "\n",
    "Public authorities have information about how people move through the city and use this data to improve user travel experience and infrastructure\n",
    "\n",
    "Dataset - contains geolocation records from Atlanta, Georgia, US\n",
    "814262 entries, representing a 1 day journey April 4th\n",
    "Each device id, idenfied by hash represents \n",
    "Trajectory_id - unique identifier for trajectory, a subsection of a journey\n",
    "For each trajectory:\n",
    "Set of entry and exit coordinates (x_entry, y_entry)  (x_exit, y_exit)\n",
    "times (time_entry, time_exit)\n",
    "V_max, V_min, V_mean - maximum, minimum, and mean speed during a trajectory\n",
    "\n",
    "## Task ##\n",
    "Produce model to help authorities understand the journeys of citizens while they move through the city\n",
    "Predict how many people are in the city center between 15:00 and 16:00\n",
    "Predict exit point of last entry in data_test.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "df = pd.read_csv(\"data_train.csv\")\n",
    "df2 = pd.read_csv(\"data_test.csv\")\n",
    "\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace=True)\n",
    "df2.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Time \n",
    "df[\"time_entry\"] = pd.to_datetime(df[\"time_entry\"]) \n",
    "df[\"time_exit\"] =  pd.to_datetime(df[\"time_exit\"])\n",
    "df[\"time_entry_val\"] = df[\"time_entry\"].dt.hour * 60 * 60  + df[\"time_entry\"].dt.minute * 60 + df[\"time_entry\"].dt.second\n",
    "df[\"time_exit_val\"] = df[\"time_exit\"].dt.hour * 60 * 60  + df[\"time_exit\"].dt.minute * 60 + df[\"time_exit\"].dt.second\n",
    "df[\"time_delta\"] = df[\"time_exit_val\"] - df[\"time_entry_val\"] #possibility statistically significant difference\n",
    "\n",
    "\n",
    "#Spatial\n",
    "[x_lower, x_upper, y_lower, y_upper] = [3750901.5068,3770901.5068, -19268905.6133,-19208905.6133]\n",
    "df[\"x_dist_start\"] = 0\n",
    "df[\"y_dist_start\"] = 0\n",
    "df.loc[((df[\"x_entry\"] < x_lower) | (df[\"x_entry\"] > x_upper)), \"x_dist_start\"] = pd.concat([(df[\"x_entry\"]-x_lower).abs(),(df[\"x_entry\"]-x_upper).abs()],axis=1).min(axis=1)\n",
    "df.loc[((df[\"y_entry\"] < y_lower) | (df[\"y_entry\"] > y_upper)), \"y_dist_start\"] = pd.concat([(df[\"y_entry\"]-y_lower).abs(),(df[\"y_entry\"]-y_upper).abs()],axis=1).min(axis=1)\n",
    "df[\"dist_start\"] = np.sqrt(df[\"x_dist_start\"] * df[\"x_dist_start\"] + df[\"y_dist_start\"] * df[\"y_dist_start\"])\n",
    "\n",
    "df[\"incitycenter_end\"] = (df[\"x_exit\"] >= x_lower) & (df[\"x_exit\"] <= x_upper) & (df[\"y_exit\"] >= y_lower) & (df[\"y_exit\"] <= y_upper)\n",
    "\n",
    "df_test = df[df[\"time_entry\"].dt.hour >= 15]\n",
    "df_train = df[df[\"time_entry\"].dt.hour < 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hash                  433077\n",
       "trajectory_id         433077\n",
       "time_entry            433077\n",
       "time_exit             433077\n",
       "vmax                  159935\n",
       "vmin                  159935\n",
       "vmean                 159935\n",
       "x_entry               433077\n",
       "y_entry               433077\n",
       "x_exit                433077\n",
       "y_exit                433077\n",
       "time_traject          433077\n",
       "peak_hour             433077\n",
       "incitycenter_end      433077\n",
       "incitycenter_start    433077\n",
       "x_dist_start          433077\n",
       "y_dist_start          433077\n",
       "dist_start            433077\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data exploration\n",
    "\n",
    "\n",
    "#134063 vehicles in train, 33515 in test - identified by hash\n",
    "\n",
    "# 814262 entries in training set df.count()\n",
    "# 698631 entries in train with time < 15:00 \n",
    "# 115631 entries in train with time > 15:00\n",
    "# 134063 unique vehicles in train \n",
    "#df[\"hash\"].nunique(), 133077 < 15:00, 115631 > 15:00\n",
    "\n",
    "# 202937 in test - identfied by trajectory id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Time - no missing entries\n",
    "\n",
    "#time_entry increasing\n",
    "#df_train[\"time_entry\"].hist(bins=160,xrot=90)\n",
    "#plt.show()\n",
    "\n",
    "#for train set in training data, i.e. time entry < 15:00\n",
    "\n",
    "#increasing on hour\n",
    "#df_train[\"time_entry\"].dt.hour.hist(bins=60)\n",
    "#plt.show()\n",
    "\n",
    "#increasing on minute\n",
    "#df_train[\"time_entry\"].dt.minute.hist(bins=60)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for test set in training data, i.e. time_entry >= 15:00\n",
    "\n",
    "#time_entry is decreasing for time_entry > 15:00\n",
    "#df_test[\"time_entry\"].hist(bins=100)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#time_entry is decreasing every minute\n",
    "#df_test[\"time_entry\"].dt.minute.hist(bins=60)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#for both train, test in training data\n",
    "#time_entry is greatest at 0 secs, decreasing from 0-20, drops sharply at 20-30,\n",
    "#spikes back up at 30-40, plummets back at 50-60\n",
    "#df_test[\"time_entry\"].dt.second.hist(bins=60)\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Velocity\n",
    "#missing entraies for vmax, vmin, vmean\n",
    "#256769 entries where vmean, vmax, vmin are complete, 243431 entries where they are all equal, 13338 where they are not\n",
    "#vmean = (vmax + vmin) / 2\n",
    "#Looks like pareto distribution, mean 2.454799, std 7.160578, min -1.000000, 25% 0.000000, 50%  0.000000, 75% 0.440000, Max - 160\n",
    "#vmean is mostly between [-1,~0.3], otherwise it is decreasing, up to ~ 40\n",
    "#variation in velocity for 14009 entries, i.e. vmin /= vmax \n",
    "\n",
    "#print((df[df[\"incitycenter_end\"]==True][\"vmean\"].dropna()).describe())\n",
    "#print((df[df[\"incitycenter_end\"]==False][\"vmean\"].dropna()).describe())\n",
    "#stats.ttest_ind(df[df[\"incitycenter_end\"]==True][\"vmean\"].dropna(), df[df[\"incitycenter_end\"]==False][\"vmean\"].dropna(), equal_var = False)\n",
    "#there is possibly a statistically significant difference in the mean velocity of those that end in the city center\n",
    "#and those that end outside, being that those outside are faster\n",
    "\n",
    "\n",
    "#Spatial - no missing entries\n",
    "#(df[\"y_exit\"]-df[\"y_entry\"]).describe() \n",
    "#change in y had mean = -287.987670, std = 35436.587832, min = -324150.485771, 320330.353105, \n",
    "#25%,50%, 75% - 0\n",
    "\n",
    "#(df[\"x_exit\"]-df[\"x_entry\"]).describe() \n",
    "#change in y had mean = 14.735629, std = 3803.295380, min = -35015.545829, max = 35696.821113\n",
    "\n",
    "#because velocity ~ 0, x_entry roughly equals x_exit, y_entry roughly equals y_exit, relative to inital coords, thus \n",
    "# if they are in the city center at the start, they are likely to be in the city center at the end\n",
    "\n",
    "#distance from start seems to follow pareto distribution, like velocity, with most distances being ~ 0 and decreasing\n",
    "\n",
    "#no correlation between distance and vm\n",
    "\n",
    "\n",
    "#area = (x_upper - x_lower) * (y_upper - y_lower)\n",
    "\n",
    "\n",
    "#print((df[df[\"incitycenter_end\"]==True][\"dist_start\"].dropna()).describe())\n",
    "#print((df[df[\"incitycenter_end\"]==False][\"dist_start\"].dropna()).describe())\n",
    "#pd.crosstab(df[\"close\"],df[\"incitycenter_end\"])\n",
    "#there is possibly a statistically significant difference in the starting distance from the city\n",
    "#of those that end in the city center and those that end outside, being that those with a higher starting distance\n",
    "#are less likely to be in the city at the end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df[\"time_entry\"] = pd.to_datetime(df[\"time_entry\"])\n",
    "#df[\"time_exit\"] = pd.to_datetime(df[\"time_exit\"])\n",
    "#df[df[\"time_exit\"].dt.hour >= 15][\"time_entry\"].hist(xrot=90)\n",
    "#plt.show()\n",
    "#print(df[(df[\"time_exit\"].dt.hour >= 15) & (df[\"time_entry\"] != df[\"time_exit\"])][[\"time_entry\",\"time_exit\"]])\n",
    "\n",
    "#((df[\"dist_start\"] / df[\"vmean\"]).dropna()).value_counts()\n",
    "#df[\"time_entry\"] = df[\"time_entry\"].dt.hour\n",
    "#df[\"time_entry\"] = df[\"time_entry\"].astype(int)\n",
    "#df[\"time_exit\"] = df[\"time_exit\"].astype(int)\n",
    "#df[\"time_exit\"] = df[\"time_entry\"].dt.hour\n",
    "\n",
    "#df[\"time_entry\"] = df[\"time_entry\"].dt.hour\n",
    "#df[\"time_exit\"] = df[\"time_exit\"].dt.hour\n",
    "df[df[\"time_traject\"] == 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Features\n",
    "#distance from city center at start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9cd1a412c5b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#Logistic Regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1284\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1285\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    748\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    575\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 577\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 2)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "#model\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "##X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.75,random_state=42)\n",
    "\n",
    "X_train = df_train[[\"x_dist_start\"]].values.reshape(-1,2)\n",
    "y_train = df_train[\"incitycenter_end\"]\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42, solver='lbfgs').fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#model2 = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "\n",
    "#SVG\n",
    "#from sklearn import svm\n",
    "#model3 = svm.SVC().fit(X_train, y_train)\n",
    "\n",
    "#Neural Network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#model4 = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "#model4.fit(X_train,y_train)\n",
    "\n",
    "#KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preprocess validation set\n",
    "df2[\"time_entry\"] = pd.to_datetime(df2[\"time_entry\"]) \n",
    "df2[\"time_exit\"] =  pd.to_datetime(df2[\"time_exit\"])\n",
    "df2[\"time_entry_val\"] = df2[\"time_entry\"].dt.hour * 60 * 60  + df2[\"time_entry\"].dt.minute * 60 + df2[\"time_entry\"].dt.second\n",
    "df2[\"time_exit_val\"] = df2[\"time_exit\"].dt.hour * 60 * 60  + df2[\"time_exit\"].dt.minute * 60 + df2[\"time_exit\"].dt.second\n",
    "df2[\"time_delta\"] = df2[\"time_exit_val\"] - df2[\"time_entry_val\"]\n",
    "\n",
    "[x_lower, x_upper, y_lower, y_upper] = [3750901.5068,3770901.5068, -19268905.6133,-19208905.6133]\n",
    "df2[\"x_dist_start\"] = 0\n",
    "df2[\"y_dist_start\"] = 0\n",
    "df2.loc[((df2[\"x_entry\"] < x_lower) | (df2[\"x_entry\"] > x_upper)), \"x_dist_start\"] = pd.concat([(df2[\"x_entry\"]-x_lower).abs(),(df2[\"x_entry\"]-x_upper).abs()],axis=1).min(axis=1)\n",
    "df2.loc[((df2[\"y_entry\"] < y_lower) | (df2[\"y_entry\"] > y_upper)), \"y_dist_start\"] = pd.concat([(df2[\"y_entry\"]-y_lower).abs(),(df2[\"y_entry\"]-y_upper).abs()],axis=1).min(axis=1)\n",
    "df2[\"dist_start\"] = np.sqrt(df2[\"x_dist_start\"] * df2[\"x_dist_start\"] + df2[\"y_dist_start\"] * df2[\"y_dist_start\"])\n",
    "\n",
    "df2[\"incitycenter_end\"] = (df2[\"x_exit\"] >= x_lower) & (df2[\"x_exit\"] <= x_upper) & (df2[\"y_exit\"] >= y_lower) & (df2[\"y_exit\"] <= y_upper)\n",
    "df2[\"incitycenter_start\"] = (df2[\"x_entry\"] >= x_lower) & (df2[\"x_entry\"] <= x_upper) & (df2[\"y_entry\"] >= y_lower) & (df2[\"y_entry\"] <= y_upper)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = df2[df2[\"time_exit\"].dt.hour > 15]\n",
    "\n",
    "X_pred = output[\"incitycenter_start\"].values.reshape(-1,1)\n",
    "output[\"target\"] = model.predict(X_pred)\n",
    "output[['trajectory_id','target']]\n",
    "output['target'] *= 1\n",
    "output.rename(index=str,columns={\"trajectory_id\":\"id\"},inplace=True)\n",
    "output[['id','target']].to_csv(\"output.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
